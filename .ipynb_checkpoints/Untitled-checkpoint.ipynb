{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text corpus to generative text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbyford/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochSize = 100\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data):\n",
    "    \n",
    "    # splits corpus on return - change if you want a different split\n",
    "    corpus = data.lower().split(\"\\n\") \n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    \n",
    "    return predictors, label, max_sequence_len, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, hidden_size, input_length=max_sequence_len-1))\n",
    "    model.add(LSTM(hidden_size, return_sequences = True))\n",
    "    \n",
    "    #model.add(LSTM(125))\n",
    "    \n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(predictors, label, epochs=epochSize, verbose=1, callbacks=[earlystop])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('data.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 5.6271 - acc: 0.0341\n",
      "Epoch 2/100\n",
      "675/675 [==============================] - 12s 18ms/step - loss: 5.3262 - acc: 0.0356\n",
      "Epoch 3/100\n",
      "675/675 [==============================] - 12s 17ms/step - loss: 5.2477 - acc: 0.0504\n",
      "Epoch 4/100\n",
      "675/675 [==============================] - 8s 12ms/step - loss: 5.2149 - acc: 0.0504\n",
      "Epoch 5/100\n",
      "675/675 [==============================] - 13s 19ms/step - loss: 5.2104 - acc: 0.0356\n",
      "Epoch 6/100\n",
      "675/675 [==============================] - 9s 14ms/step - loss: 5.2020 - acc: 0.0504\n",
      "Epoch 7/100\n",
      "675/675 [==============================] - 13s 20ms/step - loss: 5.1970 - acc: 0.0504\n",
      "Epoch 8/100\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 5.1990 - acc: 0.0400\n",
      "Epoch 9/100\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 5.1946 - acc: 0.0430\n",
      "Epoch 10/100\n",
      "675/675 [==============================] - 11s 17ms/step - loss: 5.1955 - acc: 0.0504\n",
      "Epoch 11/100\n",
      "675/675 [==============================] - 13s 19ms/step - loss: 5.1938 - acc: 0.0444\n",
      "Epoch 12/100\n",
      "675/675 [==============================] - 11s 17ms/step - loss: 5.1882 - acc: 0.0504\n",
      "Epoch 13/100\n",
      "675/675 [==============================] - 14s 21ms/step - loss: 5.1912 - acc: 0.0504\n",
      "Epoch 14/100\n",
      "675/675 [==============================] - 13s 20ms/step - loss: 5.1880 - acc: 0.0356\n",
      "Epoch 15/100\n",
      "675/675 [==============================] - 15s 22ms/step - loss: 5.1673 - acc: 0.0548\n",
      "Epoch 16/100\n"
     ]
    }
   ],
   "source": [
    "predictors, label, max_sequence_len, total_words = dataset_preparation(data)\n",
    "model = create_model(predictors, label, max_sequence_len, total_words)\n",
    "plot_model(model, to_file='model.png')\n",
    "\n",
    "output = generate_text(\"The\", 30, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So in in in in in in in in in in\n"
     ]
    }
   ],
   "source": [
    "output = generate_text(\"So\", 10, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
