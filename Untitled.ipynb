{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text corpus to generative text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbyford/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochSize = 100\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_preparation(data):\n",
    "    \n",
    "    # splits corpus on return - change if you want a different split\n",
    "    corpus = data.lower().split(\"^\") \n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    \n",
    "    return predictors, label, max_sequence_len, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label, max_sequence_len, total_words):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, hidden_size, input_length=max_sequence_len-1))\n",
    "    model.add(LSTM(hidden_size, return_sequences = True))\n",
    "    \n",
    "    #model.add(LSTM(125))\n",
    "    \n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    earlystop = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(predictors, label, epochs=epochSize, verbose=1, callbacks=[earlystop])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('data.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5326/5326 [==============================] - 570s 107ms/step - loss: 6.4186 - acc: 0.0466\n",
      "Epoch 2/100\n",
      "5326/5326 [==============================] - 572s 107ms/step - loss: 6.0494 - acc: 0.0516\n",
      "Epoch 3/100\n",
      "5326/5326 [==============================] - 569s 107ms/step - loss: 5.8978 - acc: 0.0586\n",
      "Epoch 4/100\n",
      "5326/5326 [==============================] - 569s 107ms/step - loss: 5.7591 - acc: 0.0678\n",
      "Epoch 5/100\n",
      "5326/5326 [==============================] - 567s 107ms/step - loss: 5.6477 - acc: 0.0760\n",
      "Epoch 6/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 5.5994 - acc: 0.0727\n",
      "Epoch 7/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 5.4559 - acc: 0.0813\n",
      "Epoch 8/100\n",
      "5326/5326 [==============================] - 574s 108ms/step - loss: 5.3324 - acc: 0.0909\n",
      "Epoch 9/100\n",
      "5326/5326 [==============================] - 573s 108ms/step - loss: 5.2215 - acc: 0.0993\n",
      "Epoch 10/100\n",
      "5326/5326 [==============================] - 573s 108ms/step - loss: 5.0937 - acc: 0.1177\n",
      "Epoch 11/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 4.9653 - acc: 0.1301\n",
      "Epoch 12/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 4.8362 - acc: 0.1376\n",
      "Epoch 13/100\n",
      "5326/5326 [==============================] - 567s 107ms/step - loss: 4.7144 - acc: 0.1472\n",
      "Epoch 14/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 4.5965 - acc: 0.1525\n",
      "Epoch 15/100\n",
      "5326/5326 [==============================] - 570s 107ms/step - loss: 4.4798 - acc: 0.1632\n",
      "Epoch 16/100\n",
      "5326/5326 [==============================] - 571s 107ms/step - loss: 4.3626 - acc: 0.1682\n",
      "Epoch 17/100\n",
      "5326/5326 [==============================] - 574s 108ms/step - loss: 4.2492 - acc: 0.1771\n",
      "Epoch 18/100\n",
      "5326/5326 [==============================] - 572s 107ms/step - loss: 4.1277 - acc: 0.1846\n",
      "Epoch 19/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 4.0044 - acc: 0.1964\n",
      "Epoch 20/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 3.9021 - acc: 0.2018\n",
      "Epoch 21/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 3.7694 - acc: 0.2163\n",
      "Epoch 22/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 3.6385 - acc: 0.2311\n",
      "Epoch 23/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 3.5101 - acc: 0.2507\n",
      "Epoch 24/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 3.3884 - acc: 0.2674\n",
      "Epoch 25/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 3.2646 - acc: 0.2903\n",
      "Epoch 26/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 3.1304 - acc: 0.3124\n",
      "Epoch 27/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 3.0120 - acc: 0.3389\n",
      "Epoch 28/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 2.8814 - acc: 0.3654\n",
      "Epoch 29/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 2.7626 - acc: 0.3971\n",
      "Epoch 30/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 2.6548 - acc: 0.4168\n",
      "Epoch 31/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 2.5498 - acc: 0.4397\n",
      "Epoch 32/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 2.4415 - acc: 0.4632\n",
      "Epoch 33/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 2.3370 - acc: 0.4840\n",
      "Epoch 34/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 2.2453 - acc: 0.5036\n",
      "Epoch 35/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 2.1420 - acc: 0.5267\n",
      "Epoch 36/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 2.0668 - acc: 0.5451\n",
      "Epoch 37/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 2.0167 - acc: 0.5522\n",
      "Epoch 38/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.8998 - acc: 0.5787\n",
      "Epoch 39/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.8228 - acc: 0.6018\n",
      "Epoch 40/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 1.7325 - acc: 0.6232\n",
      "Epoch 41/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.6447 - acc: 0.6412\n",
      "Epoch 42/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.5751 - acc: 0.6609\n",
      "Epoch 43/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 1.4935 - acc: 0.6808\n",
      "Epoch 44/100\n",
      "5326/5326 [==============================] - 569s 107ms/step - loss: 1.4325 - acc: 0.6934\n",
      "Epoch 45/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.3738 - acc: 0.7105\n",
      "Epoch 46/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 1.3110 - acc: 0.7281\n",
      "Epoch 47/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 1.2425 - acc: 0.7435\n",
      "Epoch 48/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 1.1777 - acc: 0.7634\n",
      "Epoch 49/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.1199 - acc: 0.7751\n",
      "Epoch 50/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 1.0634 - acc: 0.7890\n",
      "Epoch 51/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 1.0198 - acc: 0.7993\n",
      "Epoch 52/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.9628 - acc: 0.8121\n",
      "Epoch 53/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.9186 - acc: 0.8256\n",
      "Epoch 54/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.8796 - acc: 0.8312\n",
      "Epoch 55/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.8295 - acc: 0.8443\n",
      "Epoch 56/100\n",
      "5326/5326 [==============================] - 562s 105ms/step - loss: 0.7833 - acc: 0.8579\n",
      "Epoch 57/100\n",
      "5326/5326 [==============================] - 562s 106ms/step - loss: 0.7404 - acc: 0.8689\n",
      "Epoch 58/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.7035 - acc: 0.8719\n",
      "Epoch 59/100\n",
      "5326/5326 [==============================] - 562s 106ms/step - loss: 0.6632 - acc: 0.8853\n",
      "Epoch 60/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.6252 - acc: 0.8958\n",
      "Epoch 61/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.5932 - acc: 0.8984\n",
      "Epoch 62/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.5529 - acc: 0.9087\n",
      "Epoch 63/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.5297 - acc: 0.9185\n",
      "Epoch 64/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.4995 - acc: 0.9260\n",
      "Epoch 65/100\n",
      "5326/5326 [==============================] - 562s 106ms/step - loss: 0.4778 - acc: 0.9236\n",
      "Epoch 66/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.4491 - acc: 0.9347\n",
      "Epoch 67/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 0.4185 - acc: 0.9395\n",
      "Epoch 68/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.3990 - acc: 0.9442\n",
      "Epoch 69/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.3739 - acc: 0.9493\n",
      "Epoch 70/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.3514 - acc: 0.9531\n",
      "Epoch 71/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.3254 - acc: 0.9598\n",
      "Epoch 72/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.3072 - acc: 0.9615\n",
      "Epoch 73/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 0.2924 - acc: 0.9651\n",
      "Epoch 74/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 0.2722 - acc: 0.9686\n",
      "Epoch 75/100\n",
      "5326/5326 [==============================] - 564s 106ms/step - loss: 0.2567 - acc: 0.9673\n",
      "Epoch 76/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 0.2466 - acc: 0.9700\n",
      "Epoch 77/100\n",
      "5326/5326 [==============================] - 565s 106ms/step - loss: 0.2288 - acc: 0.9728\n",
      "Epoch 78/100\n",
      "5326/5326 [==============================] - 567s 107ms/step - loss: 0.2136 - acc: 0.9754\n",
      "Epoch 79/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.2003 - acc: 0.9765\n",
      "Epoch 80/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 0.1890 - acc: 0.9767\n",
      "Epoch 81/100\n",
      "5326/5326 [==============================] - 567s 107ms/step - loss: 0.1762 - acc: 0.9792\n",
      "Epoch 82/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1662 - acc: 0.9805\n",
      "Epoch 83/100\n",
      "5326/5326 [==============================] - 577s 108ms/step - loss: 0.1556 - acc: 0.9810\n",
      "Epoch 84/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 0.1490 - acc: 0.9818\n",
      "Epoch 85/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1383 - acc: 0.9820\n",
      "Epoch 86/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1351 - acc: 0.9825\n",
      "Epoch 87/100\n",
      "5326/5326 [==============================] - 569s 107ms/step - loss: 0.1418 - acc: 0.9808\n",
      "Epoch 88/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1219 - acc: 0.9824\n",
      "Epoch 89/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1102 - acc: 0.9837\n",
      "Epoch 90/100\n",
      "5326/5326 [==============================] - 568s 107ms/step - loss: 0.1051 - acc: 0.9857\n",
      "Epoch 91/100\n",
      "5326/5326 [==============================] - 567s 106ms/step - loss: 0.1000 - acc: 0.9857\n",
      "Epoch 92/100\n",
      "5326/5326 [==============================] - 567s 107ms/step - loss: 0.1022 - acc: 0.9839\n",
      "Epoch 93/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 0.0947 - acc: 0.9857\n",
      "Epoch 94/100\n",
      "5326/5326 [==============================] - 563s 106ms/step - loss: 0.1024 - acc: 0.9835\n",
      "Epoch 95/100\n",
      "5326/5326 [==============================] - 566s 106ms/step - loss: 0.0891 - acc: 0.9839\n",
      "Epoch 96/100\n",
      "5326/5326 [==============================] - 570s 107ms/step - loss: 0.0828 - acc: 0.9854\n",
      "Epoch 97/100\n",
      "5326/5326 [==============================] - 569s 107ms/step - loss: 0.0777 - acc: 0.9857\n",
      "Epoch 98/100\n",
      "5326/5326 [==============================] - 604s 113ms/step - loss: 0.0816 - acc: 0.9839\n",
      "Epoch 99/100\n",
      "5326/5326 [==============================] - 604s 113ms/step - loss: 0.0927 - acc: 0.9825\n",
      "Epoch 100/100\n",
      "5326/5326 [==============================] - 579s 109ms/step - loss: 0.1193 - acc: 0.9816\n",
      "The there are concerns about algorithms’ opacity the code of algorithms may be unviewable in systems that are proprietary or outsourced even if viewable the code may be essentially uncheckable if\n"
     ]
    }
   ],
   "source": [
    "predictors, label, max_sequence_len, total_words = dataset_preparation(data)\n",
    "model = create_model(predictors, label, max_sequence_len, total_words)\n",
    "plot_model(model, to_file='model.png')\n",
    "\n",
    "output = generate_text(\"The\", 30, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So alignment highly demonstrate that the potential to improve outcomes enhance\n"
     ]
    }
   ],
   "source": [
    "output = generate_text(\"So\", 10, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI and social good ai offers great potential for promoting the public good for example in the realms of education housing public health and sustainability we see great value in collaborating with public and private organizations including academia scientific societies ngos social entrepreneurs and interested private citizens to promote discussions and catalyze efforts to address society’s most pressing challenges some of these projects may address deep societal challenges and will be moonshots – ambitious big bets that could have far reaching impacts others may be creative ideas that could quickly produce positive results by harnessing ai advances are widely shared and\n"
     ]
    }
   ],
   "source": [
    "output = generate_text(\"AI\", 100, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "print(max_sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goals and developing is their pricing by humans if we are providing general purpose tools integrating tools for customers or developing custom solutions for this are the benefits and potential risks of their products and the actions they have taken to deliver benefits and avoid minimise or mitigate the risks they must ensure that processes are in place to address the concerns and complaints of users and other parties and that these are transparent we believe that effective communication when coupled with a principled approach to ethical considerations is a competitive advantage and will lead to progress even when hard moral\n"
     ]
    }
   ],
   "source": [
    "output = generate_text(\"Goals\", 100, max_sequence_len)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
